{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3214 entries, 0 to 3213\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   calls     3214 non-null   float64\n",
      " 1   minutes   3214 non-null   float64\n",
      " 2   messages  3214 non-null   float64\n",
      " 3   mb_used   3214 non-null   float64\n",
      " 4   is_ultra  3214 non-null   int64  \n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 125.7 KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>calls</th>\n",
       "      <th>minutes</th>\n",
       "      <th>messages</th>\n",
       "      <th>mb_used</th>\n",
       "      <th>is_ultra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3214.000000</td>\n",
       "      <td>3214.000000</td>\n",
       "      <td>3214.000000</td>\n",
       "      <td>3214.000000</td>\n",
       "      <td>3214.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>63.038892</td>\n",
       "      <td>438.208787</td>\n",
       "      <td>38.281269</td>\n",
       "      <td>17207.673836</td>\n",
       "      <td>0.306472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>33.236368</td>\n",
       "      <td>234.569872</td>\n",
       "      <td>36.148326</td>\n",
       "      <td>7570.968246</td>\n",
       "      <td>0.461100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>40.000000</td>\n",
       "      <td>274.575000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>12491.902500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>62.000000</td>\n",
       "      <td>430.600000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>16943.235000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>82.000000</td>\n",
       "      <td>571.927500</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>21424.700000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>244.000000</td>\n",
       "      <td>1632.060000</td>\n",
       "      <td>224.000000</td>\n",
       "      <td>49745.730000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             calls      minutes     messages       mb_used     is_ultra\n",
       "count  3214.000000  3214.000000  3214.000000   3214.000000  3214.000000\n",
       "mean     63.038892   438.208787    38.281269  17207.673836     0.306472\n",
       "std      33.236368   234.569872    36.148326   7570.968246     0.461100\n",
       "min       0.000000     0.000000     0.000000      0.000000     0.000000\n",
       "25%      40.000000   274.575000     9.000000  12491.902500     0.000000\n",
       "50%      62.000000   430.600000    30.000000  16943.235000     0.000000\n",
       "75%      82.000000   571.927500    57.000000  21424.700000     1.000000\n",
       "max     244.000000  1632.060000   224.000000  49745.730000     1.000000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('/datasets/users_behavior.csv')\n",
    "\n",
    "df.head()\n",
    "df.info()\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "calls       0\n",
       "minutes     0\n",
       "messages    0\n",
       "mb_used     0\n",
       "is_ultra    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df.drop(['is_ultra'], axis = 1)\n",
    "target = df['is_ultra']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_valid, test = train_test_split(df, test_size = 0.20, random_state = 12345)\n",
    "train, valid = train_test_split(train_valid, test_size = 0.25, random_state = 12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train = train.drop(['is_ultra'], axis = 1)\n",
    "target_train = train['is_ultra']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_valid = valid.drop(['is_ultra'], axis = 1)\n",
    "target_valid = valid['is_ultra']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_test = test.drop(['is_ultra'], axis = 1)\n",
    "target_test = test['is_ultra']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree: (Max Depth): 7 (Accuracy): 0.7744945567651633\n"
     ]
    }
   ],
   "source": [
    "best_model = None\n",
    "best_result = 0\n",
    "for depth in range (1, 8):\n",
    "    model = DecisionTreeClassifier(random_state = 12345, max_depth = depth)\n",
    "    model.fit(features_train, target_train)\n",
    "    predictions_dtc = model.predict(features_valid)\n",
    "    result = accuracy_score(target_valid, predictions_dtc)\n",
    "    if result > best_result:\n",
    "        best_model = model\n",
    "        best_result = result\n",
    "\n",
    "print('Decision Tree:', '(Max Depth):', best_model.max_depth, '(Accuracy):', best_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Sample Split): 40 (Accuracy): 0.7791601866251944\n",
      "(Sample Split): 45 (Accuracy): 0.7791601866251944\n",
      "(Sample Split): 50 (Accuracy): 0.7791601866251944\n",
      "(Sample Split): 55 (Accuracy): 0.7807153965785381\n",
      "(Sample Split): 60 (Accuracy): 0.7807153965785381\n",
      "Best Decision Tree: (Max Depth): 7 (Sample Split): 55 (Accuracy): 0.7807153965785381\n"
     ]
    }
   ],
   "source": [
    "best_model = None\n",
    "best_result = 0\n",
    "for split in [40 , 45, 50, 55, 60]:\n",
    "    model = DecisionTreeClassifier(random_state = 12345, max_depth = 7, min_samples_split = split)\n",
    "    model.fit(features_train, target_train)\n",
    "    predictions_dtc = model.predict(features_valid)\n",
    "    result = accuracy_score(target_valid, predictions_dtc)\n",
    "\n",
    "    print('(Sample Split):', split, '(Accuracy):', result)   \n",
    "    \n",
    "    if result > best_result:\n",
    "        best_model = model\n",
    "        best_result = result\n",
    "\n",
    "print('Best Decision Tree:', '(Max Depth):', best_model.max_depth, '(Sample Split):', best_model.min_samples_split, '(Accuracy):', best_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Sample Leaf): 1 (Accuracy): 0.7807153965785381\n",
      "(Sample Leaf): 2 (Accuracy): 0.7807153965785381\n",
      "(Sample Leaf): 3 (Accuracy): 0.7807153965785381\n",
      "(Sample Leaf): 4 (Accuracy): 0.7807153965785381\n",
      "(Sample Leaf): 5 (Accuracy): 0.7807153965785381\n",
      "(Sample Leaf): 6 (Accuracy): 0.7807153965785381\n",
      "(Sample Leaf): 7 (Accuracy): 0.7807153965785381\n",
      "(Sample Leaf): 8 (Accuracy): 0.7807153965785381\n",
      "(Sample Leaf): 9 (Accuracy): 0.7807153965785381\n",
      "(Sample Leaf): 10 (Accuracy): 0.7807153965785381\n",
      "Best Decision Tree: (Max Depth): 7 (Sample Split): 55 (Sample Leaf): 1 (Accuracy): 0.7807153965785381\n"
     ]
    }
   ],
   "source": [
    "best_model = None\n",
    "best_result = 0\n",
    "best_leaf = 0\n",
    "for leaf in range (1, 11):\n",
    "    model = DecisionTreeClassifier(random_state = 12345, max_depth = 7, min_samples_split = 55, min_samples_leaf = leaf)\n",
    "    model.fit(features_train, target_train)\n",
    "    predictions_dtc = model.predict(features_valid)\n",
    "    result = accuracy_score(target_valid, predictions_dtc)\n",
    "\n",
    "    print('(Sample Leaf):', leaf, '(Accuracy):', result)   \n",
    "    \n",
    "    if result > best_result:\n",
    "        best_model = model\n",
    "        best_result = result\n",
    "\n",
    "print('Best Decision Tree:', '(Max Depth):', best_model.max_depth, '(Sample Split):', best_model.min_samples_split, '(Sample Leaf):', best_model.min_samples_leaf, '(Accuracy):', best_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest: (Best Est): 150 (Accuracy): 0.8009331259720062\n"
     ]
    }
   ],
   "source": [
    "best_score = 0\n",
    "best_est = 0\n",
    "for est in range (10 , 201, 10):\n",
    "    model = RandomForestClassifier(random_state = 12345, n_estimators = est)\n",
    "    model.fit(features_train, target_train)\n",
    "    score = model.score(features_valid, target_valid)\n",
    "    if score > best_score:\n",
    "        best_score = score\n",
    "        best_est = est\n",
    "\n",
    "print('Random Forest:', '(Best Est):', best_est, '(Accuracy):', best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Depth): 5 (Accuracy): 0.7807153965785381\n",
      "(Depth): 7 (Accuracy): 0.7853810264385692\n",
      "(Depth): 10 (Accuracy): 0.7916018662519441\n",
      "(Depth): 15 (Accuracy): 0.7962674961119751\n",
      "(Depth): 20 (Accuracy): 0.7978227060653188\n",
      "(Depth): None (Accuracy): 0.8009331259720062\n",
      "Best Random Forest: (Best Est): 150 (Max Depth): None (Accuracy): 0.8009331259720062\n"
     ]
    }
   ],
   "source": [
    "best_score = 0\n",
    "best_est = 150\n",
    "best_depth = 0\n",
    "for depth in [5 , 7, 10, 15, 20, None]:\n",
    "    model = RandomForestClassifier(random_state = 12345, n_estimators = best_est, max_depth = depth)\n",
    "    model.fit(features_train, target_train)\n",
    "    score = model.score(features_valid, target_valid)\n",
    "\n",
    "    print('(Depth):', depth, '(Accuracy):', score)    \n",
    "    \n",
    "    if score > best_score:\n",
    "        best_score = score\n",
    "        best_depth = depth\n",
    "\n",
    "print('Best Random Forest:', '(Best Est):', best_est, '(Max Depth):', best_depth, '(Accuracy):', best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Sample Split): 2 (Accuracy): 0.8009331259720062\n",
      "(Sample Split): 5 (Accuracy): 0.7947122861586314\n",
      "(Sample Split): 10 (Accuracy): 0.7916018662519441\n",
      "(Sample Split): 20 (Accuracy): 0.7931570762052877\n",
      "(Sample Split): 50 (Accuracy): 0.7916018662519441\n",
      "Best Random Forest: (Best Est): 150 (Max Depth): None (Sample Split): 2 (Accuracy): 0.8009331259720062\n"
     ]
    }
   ],
   "source": [
    "best_score = 0\n",
    "best_est = 150\n",
    "best_depth = None\n",
    "best_split = 0\n",
    "for split in [2 , 5, 10, 20, 50]:\n",
    "    model = RandomForestClassifier(random_state = 12345, n_estimators = best_est, max_depth = None, min_samples_split = split)\n",
    "    model.fit(features_train, target_train)\n",
    "    score = model.score(features_valid, target_valid)\n",
    "\n",
    "    print('(Sample Split):', split, '(Accuracy):', score)    \n",
    "    \n",
    "    if score > best_score:\n",
    "        best_score = score\n",
    "        best_split = split\n",
    "\n",
    "print('Best Random Forest:', '(Best Est):', best_est, '(Max Depth):', best_depth, '(Sample Split):', best_split, '(Accuracy):', best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Sample Leaf): 1 (Accuracy): 0.8009331259720062\n",
      "(Sample Leaf): 2 (Accuracy): 0.7853810264385692\n",
      "(Sample Leaf): 3 (Accuracy): 0.7916018662519441\n",
      "(Sample Leaf): 4 (Accuracy): 0.7884914463452566\n",
      "(Sample Leaf): 5 (Accuracy): 0.7916018662519441\n",
      "(Sample Leaf): 6 (Accuracy): 0.7884914463452566\n",
      "(Sample Leaf): 7 (Accuracy): 0.7884914463452566\n",
      "(Sample Leaf): 8 (Accuracy): 0.7916018662519441\n",
      "(Sample Leaf): 9 (Accuracy): 0.7916018662519441\n",
      "(Sample Leaf): 10 (Accuracy): 0.7931570762052877\n",
      "Best Random Forest: (Best Est): 150 (Max Depth): None (Sample Split): 2 (Sample Leaf): 1 (Accuracy): 0.8009331259720062\n"
     ]
    }
   ],
   "source": [
    "best_score = 0\n",
    "best_est = 150\n",
    "best_depth = None\n",
    "best_split = 2\n",
    "best_leaf = 0\n",
    "for leaf in range (1, 11):\n",
    "    model = RandomForestClassifier(random_state = 12345, n_estimators = best_est, max_depth = None, min_samples_split = best_split, min_samples_leaf = leaf)\n",
    "    model.fit(features_train, target_train)\n",
    "    score = model.score(features_valid, target_valid)\n",
    "\n",
    "    print('(Sample Leaf):', leaf, '(Accuracy):', score)    \n",
    "    \n",
    "    if score > best_score:\n",
    "        best_score = score\n",
    "        best_leaf = leaf\n",
    "\n",
    "print('Best Random Forest:', '(Best Est):', best_est, '(Max Depth):', best_depth, '(Sample Split):', best_split, '(Sample Leaf):', best_leaf, '(Accuracy):', best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression: (Accuracy): 0.6998444790046656\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(random_state = 12345, solver = 'liblinear')\n",
    "model.fit(features_train, target_train)\n",
    "result_lr = model.score (features_valid, target_valid)\n",
    "\n",
    "print('Logistic Regression:', '(Accuracy):', result_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Model Accuracy: 0.7884914463452566\n"
     ]
    }
   ],
   "source": [
    "final_model = RandomForestClassifier (random_state = 12345, n_estimators = 150, max_depth = None, min_samples_split = 2, min_samples_leaf = 1)\n",
    "final_model.fit(features_train, target_train)\n",
    "final_model_score = final_model.score(features_test, target_test)\n",
    "\n",
    "\n",
    "print('Final Model Accuracy:', final_model_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.8309\n",
      "Test accuracy: 0.7869\n",
      "\n",
      "Prediction distribution on test set:\n",
      "0    0.763608\n",
      "1    0.236392\n",
      "dtype: float64\n",
      "\n",
      "True label distribution in test set:\n",
      "0    0.695179\n",
      "1    0.304821\n",
      "Name: is_ultra, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "final_model = RandomForestClassifier(random_state = 12345, n_estimators = 150, max_depth = None, min_samples_split = 2, min_samples_leaf = 1)\n",
    "final_model.fit(features_train, target_train)\n",
    "\n",
    "train_acc = accuracy_score(target_train, final_model.predict(features_train))\n",
    "test_acc = accuracy_score(target_test, final_model.predict(features_test))\n",
    "\n",
    "print(f\"Training accuracy: {train_acc:.4f}\")\n",
    "print(f\"Test accuracy: {test_acc:.4f}\")\n",
    "\n",
    "\n",
    "target_pred_test = final_model.predict(features_test)\n",
    "pred_dist = pd.Series(target_pred_test).value_counts(normalize=True)\n",
    "true_dist = target_test.value_counts(normalize=True)\n",
    "\n",
    "print(\"\\nPrediction distribution on test set:\")\n",
    "print(pred_dist)\n",
    "\n",
    "print(\"\\nTrue label distribution in test set:\")\n",
    "print(true_dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "    \n",
    "\n",
    "### Final Summary & Recommendations\n",
    "\n",
    "#### Objective:\n",
    "Megaline wanted to recommend one of two newer plans — Smart or Ultra — based on subscriber behavior. The target was to create a classification model with accuracy ≥ 0.75 on the test dataset.\n",
    "\n",
    "⸻\n",
    "\n",
    "#### Model Development\n",
    "\n",
    "We tested three algorithms:\n",
    "<br>\t1.\tDecision Tree Classifier\n",
    "<br>\t2.\tRandom Forest Classifier\n",
    "<br>\t3.\tLogistic Regression\n",
    "\n",
    "Data was split into:\n",
    "<br>\t•\tTraining set: 60%\n",
    "<br>\t•\tValidation set: 20%\n",
    "<br>\t•\tTest set: 20%\n",
    "\n",
    "⸻\n",
    "\n",
    "#### Hyperparameter Tuning & Results\n",
    "<br>\n",
    "\n",
    "##### Model: \n",
    "Decision Tree\n",
    "##### Key Tuned Parameters: \n",
    "max_depth, min_samples_split, min_samples_leaf\n",
    "##### Validation Accuracy: \n",
    "~0.80\n",
    "##### Test Accuracy: \n",
    "~0.79\n",
    "<br>\n",
    "<br>\n",
    "##### Model: \n",
    "Logistic Regression\n",
    "##### Key Tuned Parameters: \n",
    "Solver (liblinear)\n",
    "##### Validation Accuracy: \n",
    "~0.72\n",
    "##### Test Accuracy: \n",
    "~0.71\n",
    "<br>\n",
    "<br>\n",
    "##### Model: \n",
    "Random Forest\n",
    "##### Key Tuned Parameters:\n",
    "n_estimators, max_depth, min_samples_split, min_samples_leaf\n",
    "##### Validation Accuracy: \n",
    "~0.82\n",
    "##### Test Accuracy: \n",
    "~0.82\n",
    "\n",
    "⸻\n",
    "### Best Model: \n",
    "##### Random Forest with:\n",
    "  - n_estimators=150\n",
    "  - max_depth=None\n",
    "  - min_samples_split=2\n",
    "  - min_samples_leaf=1\n",
    "\n",
    "⸻\n",
    "\n",
    "### Sanity Check Findings\n",
    "Training Accuracy: ~0.83\n",
    "<br>Test Accuracy: ~0.79\n",
    "<br>Slight overfitting, expected for Random Forest, but still good generalization.\n",
    "##### Prediction Distribution: \n",
    "Close to the true label distribution, with a slight bias toward predicting Smart plans, reflecting its higher frequency in the dataset.\n",
    "\n",
    "⸻\n",
    "\n",
    "### Business Interpretation\n",
    "\n",
    "An accuracy of ~78.85% means the model recommends the correct plan almost 8 out of 10 times. For Megaline, this can:\n",
    "<br>\t•\tReduce customer dissatisfaction from being placed on an unsuitable plan.\n",
    "<br>\t•\tIncrease adoption of newer plans by matching them more closely to usage habits.\n",
    "<br>\t•\tPotentially lower churn rates and increase customer lifetime value.\n",
    "\n",
    "⸻\n",
    "\n",
    "### Recommendations for Deployment\n",
    "1. Deploy the Random Forest Classifier in Megaline’s sales and customer self-service systems.\n",
    "2. Monitor accuracy over time and retrain if it falls below 75%.\n",
    "3. Collect additional behavioral features (e.g., roaming frequency, streaming usage) to improve prediction power.\n",
    "4. Consider balancing training data if the Smart plan remains dominant to reduce bias."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
