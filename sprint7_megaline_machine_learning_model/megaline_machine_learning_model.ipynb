{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border: solid blue 2px; padding: 15px; margin: 10px\">\n",
    "  <b>Overall Summary of the Project ‚Äì Iteration 1</b><br><br>\n",
    "\n",
    "  Hi Chelsea, I‚Äôm <b>Victor Camargo</b> (https://hub.tripleten.com/u/e9cc9c11). I‚Äôll be reviewing your project and sharing feedback using the color-coded comments below. Thanks for submitting your work!\n",
    "\n",
    "  <b>Nice work on:</b><br>\n",
    "  ‚úîÔ∏è Loading and inspecting the dataset before modeling<br>\n",
    "  ‚úîÔ∏è Splitting the data correctly into training, validation, and test sets<br>\n",
    "  ‚úîÔ∏è Testing multiple algorithms (Decision Tree, Random Forest, Logistic Regression) and performing thorough hyperparameter tuning<br>\n",
    "  ‚úîÔ∏è Selecting the Random Forest Classifier as the best-performing model with accuracy above the target threshold<br>\n",
    "  ‚úîÔ∏è Including a sanity check to compare prediction distribution to the true label distribution<br>\n",
    "  ‚úîÔ∏è Writing a clear and well-structured final summary with business interpretation and actionable recommendations<br><br>\n",
    "\n",
    "  This is a great project ‚Äî keep up this clean and structured approach for future work! ‚úÖ<br><br>\n",
    "\n",
    "  <hr>\n",
    "\n",
    "  üîπ <b>Legend:</b><br>\n",
    "  üü¢ Green = well done<br>\n",
    "  üü° Yellow = suggestions<br>\n",
    "  üî¥ Red = must fix<br>\n",
    "  üîµ Blue = your comments or questions<br><br>\n",
    "  \n",
    "  <b>Please ensure</b> that all cells run smoothly from top to bottom and display their outputs before submitting ‚Äî this helps keep your analysis easy to follow.  \n",
    "  <b>Kind reminder:</b> try not to move, change, or delete reviewer comments, as they are there to track progress and provide better support during your revisions.<br><br>\n",
    "\n",
    "  <b>Feel free to reach out if you need help in Questions channel.</b><br>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<b> Student's comment</b>\n",
    "\n",
    "Data Information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "  <b>Reviewer‚Äôs comment ‚Äì Iteration 1:</b><br>\n",
    "  Great start by importing the key libraries you‚Äôll need for this project, including <code>pandas</code> for data handling, <code>matplotlib</code> for plotting, and essential scikit-learn modules for splitting, modeling, and evaluating your data. The choice of <code>DecisionTreeClassifier</code>, <code>RandomForestClassifier</code>, and <code>LogisticRegression</code> is appropriate for this classification task.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3214 entries, 0 to 3213\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   calls     3214 non-null   float64\n",
      " 1   minutes   3214 non-null   float64\n",
      " 2   messages  3214 non-null   float64\n",
      " 3   mb_used   3214 non-null   float64\n",
      " 4   is_ultra  3214 non-null   int64  \n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 125.7 KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>calls</th>\n",
       "      <th>minutes</th>\n",
       "      <th>messages</th>\n",
       "      <th>mb_used</th>\n",
       "      <th>is_ultra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3214.000000</td>\n",
       "      <td>3214.000000</td>\n",
       "      <td>3214.000000</td>\n",
       "      <td>3214.000000</td>\n",
       "      <td>3214.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>63.038892</td>\n",
       "      <td>438.208787</td>\n",
       "      <td>38.281269</td>\n",
       "      <td>17207.673836</td>\n",
       "      <td>0.306472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>33.236368</td>\n",
       "      <td>234.569872</td>\n",
       "      <td>36.148326</td>\n",
       "      <td>7570.968246</td>\n",
       "      <td>0.461100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>40.000000</td>\n",
       "      <td>274.575000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>12491.902500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>62.000000</td>\n",
       "      <td>430.600000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>16943.235000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>82.000000</td>\n",
       "      <td>571.927500</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>21424.700000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>244.000000</td>\n",
       "      <td>1632.060000</td>\n",
       "      <td>224.000000</td>\n",
       "      <td>49745.730000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             calls      minutes     messages       mb_used     is_ultra\n",
       "count  3214.000000  3214.000000  3214.000000   3214.000000  3214.000000\n",
       "mean     63.038892   438.208787    38.281269  17207.673836     0.306472\n",
       "std      33.236368   234.569872    36.148326   7570.968246     0.461100\n",
       "min       0.000000     0.000000     0.000000      0.000000     0.000000\n",
       "25%      40.000000   274.575000     9.000000  12491.902500     0.000000\n",
       "50%      62.000000   430.600000    30.000000  16943.235000     0.000000\n",
       "75%      82.000000   571.927500    57.000000  21424.700000     1.000000\n",
       "max     244.000000  1632.060000   224.000000  49745.730000     1.000000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('/datasets/users_behavior.csv')\n",
    "\n",
    "df.head()\n",
    "df.info()\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<b> Student's comment</b>\n",
    "\n",
    "Check data for missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "calls       0\n",
       "minutes     0\n",
       "messages    0\n",
       "mb_used     0\n",
       "is_ultra    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<b> Student's comment</b>\n",
    "\n",
    "Create features and target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "  <b>Reviewer‚Äôs comment ‚Äì Iteration 1:</b><br>\n",
    "  Good job loading the dataset and inspecting it with <code>.head()</code>, <code>.info()</code>, and <code>.describe()</code>. You also checked for missing values, which is an important first step in preparing your data for modeling.\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "  <b>Reviewer‚Äôs comment ‚Äì Iteration 1:</b><br>\n",
    "  Even if there are no missing values, it‚Äôs a good practice to perform a brief exploratory data analysis (EDA) before modeling. Visualizing your features with <b>histograms</b> for distributions and <b>boxplots</b> to detect outliers helps ensure there are no hidden anomalies and gives you a better understanding of the data before training your models.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df.drop(['is_ultra'], axis = 1)\n",
    "target = df['is_ultra']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<b> Student's comment</b>\n",
    "\n",
    "Split the data into training, validation, and test set. First split by 20% for test data and 80% for training and validation data. Second split by 25% of 80% for validation data to get 20%. This puts training data at 60% split. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_valid, test = train_test_split(df, test_size = 0.20, random_state = 12345)\n",
    "train, valid = train_test_split(train_valid, test_size = 0.25, random_state = 12345)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<b> Student's comment</b>\n",
    "<br>Create training data features and target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train = train.drop(['is_ultra'], axis = 1)\n",
    "target_train = train['is_ultra']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<b> Student's comment</b>\n",
    "\n",
    "Create validation data features and target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_valid = valid.drop(['is_ultra'], axis = 1)\n",
    "target_valid = valid['is_ultra']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<b> Student's comment</b>\n",
    "<br>Create test data features and target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_test = test.drop(['is_ultra'], axis = 1)\n",
    "target_test = test['is_ultra']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "  <b>Reviewer‚Äôs comment ‚Äì Iteration 1:</b><br>\n",
    "  Excellent job splitting the data correctly into <b>training</b> (60%), <b>validation</b> (20%), and <b>test</b> (20%) sets. This approach ensures you can tune your models on the validation set while keeping the test set completely unseen until the final evaluation, which is a best practice for fair model assessment.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<b> Student's comment</b>\n",
    "\n",
    "Decision Tree Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree: (Max Depth): 7 (Accuracy): 0.7744945567651633\n"
     ]
    }
   ],
   "source": [
    "best_model = None\n",
    "best_result = 0\n",
    "for depth in range (1, 8):\n",
    "    model = DecisionTreeClassifier(random_state = 12345, max_depth = depth)\n",
    "    model.fit(features_train, target_train)\n",
    "    predictions_dtc = model.predict(features_valid)\n",
    "    result = accuracy_score(target_valid, predictions_dtc)\n",
    "    if result > best_result:\n",
    "        best_model = model\n",
    "        best_result = result\n",
    "\n",
    "print('Decision Tree:', '(Max Depth):', best_model.max_depth, '(Accuracy):', best_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<b> Student's comment</b>\n",
    "\n",
    "Decision Tree Model with Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Sample Split): 40 (Accuracy): 0.7791601866251944\n",
      "(Sample Split): 45 (Accuracy): 0.7791601866251944\n",
      "(Sample Split): 50 (Accuracy): 0.7791601866251944\n",
      "(Sample Split): 55 (Accuracy): 0.7807153965785381\n",
      "(Sample Split): 60 (Accuracy): 0.7807153965785381\n",
      "Best Decision Tree: (Max Depth): 7 (Sample Split): 55 (Accuracy): 0.7807153965785381\n"
     ]
    }
   ],
   "source": [
    "best_model = None\n",
    "best_result = 0\n",
    "for split in [40 , 45, 50, 55, 60]:\n",
    "    model = DecisionTreeClassifier(random_state = 12345, max_depth = 7, min_samples_split = split)\n",
    "    model.fit(features_train, target_train)\n",
    "    predictions_dtc = model.predict(features_valid)\n",
    "    result = accuracy_score(target_valid, predictions_dtc)\n",
    "\n",
    "    print('(Sample Split):', split, '(Accuracy):', result)   \n",
    "    \n",
    "    if result > best_result:\n",
    "        best_model = model\n",
    "        best_result = result\n",
    "\n",
    "print('Best Decision Tree:', '(Max Depth):', best_model.max_depth, '(Sample Split):', best_model.min_samples_split, '(Accuracy):', best_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Sample Leaf): 1 (Accuracy): 0.7807153965785381\n",
      "(Sample Leaf): 2 (Accuracy): 0.7807153965785381\n",
      "(Sample Leaf): 3 (Accuracy): 0.7807153965785381\n",
      "(Sample Leaf): 4 (Accuracy): 0.7807153965785381\n",
      "(Sample Leaf): 5 (Accuracy): 0.7807153965785381\n",
      "(Sample Leaf): 6 (Accuracy): 0.7807153965785381\n",
      "(Sample Leaf): 7 (Accuracy): 0.7807153965785381\n",
      "(Sample Leaf): 8 (Accuracy): 0.7807153965785381\n",
      "(Sample Leaf): 9 (Accuracy): 0.7807153965785381\n",
      "(Sample Leaf): 10 (Accuracy): 0.7807153965785381\n",
      "Best Decision Tree: (Max Depth): 7 (Sample Split): 55 (Sample Leaf): 1 (Accuracy): 0.7807153965785381\n"
     ]
    }
   ],
   "source": [
    "best_model = None\n",
    "best_result = 0\n",
    "best_leaf = 0\n",
    "for leaf in range (1, 11):\n",
    "    model = DecisionTreeClassifier(random_state = 12345, max_depth = 7, min_samples_split = 55, min_samples_leaf = leaf)\n",
    "    model.fit(features_train, target_train)\n",
    "    predictions_dtc = model.predict(features_valid)\n",
    "    result = accuracy_score(target_valid, predictions_dtc)\n",
    "\n",
    "    print('(Sample Leaf):', leaf, '(Accuracy):', result)   \n",
    "    \n",
    "    if result > best_result:\n",
    "        best_model = model\n",
    "        best_result = result\n",
    "\n",
    "print('Best Decision Tree:', '(Max Depth):', best_model.max_depth, '(Sample Split):', best_model.min_samples_split, '(Sample Leaf):', best_model.min_samples_leaf, '(Accuracy):', best_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "  <b>Reviewer‚Äôs comment ‚Äì Iteration 1:</b><br>\n",
    "  Great work tuning the <b>DecisionTreeClassifier</b> by iterating over different <code>max_depth</code>, <code>min_samples_split</code>, and <code>min_samples_leaf</code> values. Printing the results at each stage and tracking the best configuration is a clear and effective way to optimize model performance.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<b> Student's comment</b>\n",
    "\n",
    "Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest: (Best Est): 150 (Accuracy): 0.8009331259720062\n"
     ]
    }
   ],
   "source": [
    "best_score = 0\n",
    "best_est = 0\n",
    "for est in range (10 , 201, 10):\n",
    "    model = RandomForestClassifier(random_state = 12345, n_estimators = est)\n",
    "    model.fit(features_train, target_train)\n",
    "    score = model.score(features_valid, target_valid)\n",
    "    if score > best_score:\n",
    "        best_score = score\n",
    "        best_est = est\n",
    "\n",
    "print('Random Forest:', '(Best Est):', best_est, '(Accuracy):', best_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<b> Student's comment</b>\n",
    "\n",
    "Random Forest Model with hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Depth): 5 (Accuracy): 0.7807153965785381\n",
      "(Depth): 7 (Accuracy): 0.7853810264385692\n",
      "(Depth): 10 (Accuracy): 0.7916018662519441\n",
      "(Depth): 15 (Accuracy): 0.7962674961119751\n",
      "(Depth): 20 (Accuracy): 0.7978227060653188\n",
      "(Depth): None (Accuracy): 0.8009331259720062\n",
      "Best Random Forest: (Best Est): 150 (Max Depth): None (Accuracy): 0.8009331259720062\n"
     ]
    }
   ],
   "source": [
    "best_score = 0\n",
    "best_est = 150\n",
    "best_depth = 0\n",
    "for depth in [5 , 7, 10, 15, 20, None]:\n",
    "    model = RandomForestClassifier(random_state = 12345, n_estimators = best_est, max_depth = depth)\n",
    "    model.fit(features_train, target_train)\n",
    "    score = model.score(features_valid, target_valid)\n",
    "\n",
    "    print('(Depth):', depth, '(Accuracy):', score)    \n",
    "    \n",
    "    if score > best_score:\n",
    "        best_score = score\n",
    "        best_depth = depth\n",
    "\n",
    "print('Best Random Forest:', '(Best Est):', best_est, '(Max Depth):', best_depth, '(Accuracy):', best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Sample Split): 2 (Accuracy): 0.8009331259720062\n",
      "(Sample Split): 5 (Accuracy): 0.7947122861586314\n",
      "(Sample Split): 10 (Accuracy): 0.7916018662519441\n",
      "(Sample Split): 20 (Accuracy): 0.7931570762052877\n",
      "(Sample Split): 50 (Accuracy): 0.7916018662519441\n",
      "Best Random Forest: (Best Est): 150 (Max Depth): None (Sample Split): 2 (Accuracy): 0.8009331259720062\n"
     ]
    }
   ],
   "source": [
    "best_score = 0\n",
    "best_est = 150\n",
    "best_depth = None\n",
    "best_split = 0\n",
    "for split in [2 , 5, 10, 20, 50]:\n",
    "    model = RandomForestClassifier(random_state = 12345, n_estimators = best_est, max_depth = None, min_samples_split = split)\n",
    "    model.fit(features_train, target_train)\n",
    "    score = model.score(features_valid, target_valid)\n",
    "\n",
    "    print('(Sample Split):', split, '(Accuracy):', score)    \n",
    "    \n",
    "    if score > best_score:\n",
    "        best_score = score\n",
    "        best_split = split\n",
    "\n",
    "print('Best Random Forest:', '(Best Est):', best_est, '(Max Depth):', best_depth, '(Sample Split):', best_split, '(Accuracy):', best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Sample Leaf): 1 (Accuracy): 0.8009331259720062\n",
      "(Sample Leaf): 2 (Accuracy): 0.7853810264385692\n",
      "(Sample Leaf): 3 (Accuracy): 0.7916018662519441\n",
      "(Sample Leaf): 4 (Accuracy): 0.7884914463452566\n",
      "(Sample Leaf): 5 (Accuracy): 0.7916018662519441\n",
      "(Sample Leaf): 6 (Accuracy): 0.7884914463452566\n",
      "(Sample Leaf): 7 (Accuracy): 0.7884914463452566\n",
      "(Sample Leaf): 8 (Accuracy): 0.7916018662519441\n",
      "(Sample Leaf): 9 (Accuracy): 0.7916018662519441\n",
      "(Sample Leaf): 10 (Accuracy): 0.7931570762052877\n",
      "Best Random Forest: (Best Est): 150 (Max Depth): None (Sample Split): 2 (Sample Leaf): 1 (Accuracy): 0.8009331259720062\n"
     ]
    }
   ],
   "source": [
    "best_score = 0\n",
    "best_est = 150\n",
    "best_depth = None\n",
    "best_split = 2\n",
    "best_leaf = 0\n",
    "for leaf in range (1, 11):\n",
    "    model = RandomForestClassifier(random_state = 12345, n_estimators = best_est, max_depth = None, min_samples_split = best_split, min_samples_leaf = leaf)\n",
    "    model.fit(features_train, target_train)\n",
    "    score = model.score(features_valid, target_valid)\n",
    "\n",
    "    print('(Sample Leaf):', leaf, '(Accuracy):', score)    \n",
    "    \n",
    "    if score > best_score:\n",
    "        best_score = score\n",
    "        best_leaf = leaf\n",
    "\n",
    "print('Best Random Forest:', '(Best Est):', best_est, '(Max Depth):', best_depth, '(Sample Split):', best_split, '(Sample Leaf):', best_leaf, '(Accuracy):', best_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "  <b>Reviewer‚Äôs comment ‚Äì Iteration 1:</b><br>\n",
    "  Excellent work performing systematic hyperparameter tuning for the <b>RandomForestClassifier</b>. You explored <code>n_estimators</code>, <code>max_depth</code>, <code>min_samples_split</code>, and <code>min_samples_leaf</code>, recording the accuracy for each configuration and tracking the best-performing model. This structured approach makes it easy to identify optimal parameters and demonstrates a solid understanding of model tuning.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<b> Student's comment</b>\n",
    "\n",
    "Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression: (Accuracy): 0.6998444790046656\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(random_state = 12345, solver = 'liblinear')\n",
    "model.fit(features_train, target_train)\n",
    "result_lr = model.score (features_valid, target_valid)\n",
    "\n",
    "print('Logistic Regression:', '(Accuracy):', result_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<b> Student's comment</b>\n",
    "\n",
    "Random Forest Model is deemed best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Model Accuracy: 0.7884914463452566\n"
     ]
    }
   ],
   "source": [
    "final_model = RandomForestClassifier (random_state = 12345, n_estimators = 150, max_depth = None, min_samples_split = 2, min_samples_leaf = 1)\n",
    "final_model.fit(features_train, target_train)\n",
    "final_model_score = final_model.score(features_test, target_test)\n",
    "\n",
    "\n",
    "print('Final Model Accuracy:', final_model_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<b> Student's comment</b>\n",
    "\n",
    "Sanity Check Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.8309\n",
      "Test accuracy: 0.7869\n",
      "\n",
      "Prediction distribution on test set:\n",
      "0    0.763608\n",
      "1    0.236392\n",
      "dtype: float64\n",
      "\n",
      "True label distribution in test set:\n",
      "0    0.695179\n",
      "1    0.304821\n",
      "Name: is_ultra, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "final_model = RandomForestClassifier(random_state = 12345, n_estimators = 150, max_depth = None, min_samples_split = 2, min_samples_leaf = 1)\n",
    "final_model.fit(features_train, target_train)\n",
    "\n",
    "train_acc = accuracy_score(target_train, best_model.predict(features_train))\n",
    "\n",
    "test_acc = accuracy_score(target_test, best_model.predict(features_test))\n",
    "\n",
    "print(f\"Training accuracy: {train_acc:.4f}\")\n",
    "print(f\"Test accuracy: {test_acc:.4f}\")\n",
    "\n",
    "\n",
    "target_pred_test = final_model.predict(features_test)\n",
    "pred_dist = pd.Series(target_pred_test).value_counts(normalize=True)\n",
    "true_dist = target_test.value_counts(normalize=True)\n",
    "\n",
    "print(\"\\nPrediction distribution on test set:\")\n",
    "print(pred_dist)\n",
    "\n",
    "print(\"\\nTrue label distribution in test set:\")\n",
    "print(true_dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "  <b>Reviewer‚Äôs comment ‚Äì Iteration 1:</b><br>\n",
    "  Good job including <b>LogisticRegression</b> as an additional model for comparison, and then selecting <b>RandomForestClassifier</b> as the best model based on its performance. You also tested the final model on the unseen test set and included a sanity check that compares prediction distributions to the true label distribution ‚Äî this is a strong practice to validate that the model‚Äôs predictions are reasonable.\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "  <b>Reviewer‚Äôs comment ‚Äì Iteration 1:</b><br>\n",
    "  While your sanity check is valuable, be careful when referencing variables. In your final section, you trained <code>final_model</code> but then used <code>best_model</code> for accuracy calculations, which could lead to inconsistencies if <code>best_model</code> was trained on different data or parameters. Ensure that the model you evaluate is the same one you trained for the final test, so the reported metrics are accurate.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<b> Student's comment</b>\n",
    "    \n",
    "\n",
    "### Final Summary & Recommendations\n",
    "\n",
    "#### Objective:\n",
    "Megaline wanted to recommend one of two newer plans ‚Äî Smart or Ultra ‚Äî based on subscriber behavior. The target was to create a classification model with accuracy ‚â• 0.75 on the test dataset.\n",
    "\n",
    "‚∏ª\n",
    "\n",
    "#### Model Development\n",
    "\n",
    "We tested three algorithms:\n",
    "<br>\t1.\tDecision Tree Classifier\n",
    "<br>\t2.\tRandom Forest Classifier\n",
    "<br>\t3.\tLogistic Regression\n",
    "\n",
    "Data was split into:\n",
    "<br>\t‚Ä¢\tTraining set: 60%\n",
    "<br>\t‚Ä¢\tValidation set: 20%\n",
    "<br>\t‚Ä¢\tTest set: 20%\n",
    "\n",
    "‚∏ª\n",
    "\n",
    "#### Hyperparameter Tuning & Results\n",
    "<br>\n",
    "\n",
    "##### Model: \n",
    "Decision Tree\n",
    "##### Key Tuned Parameters: \n",
    "max_depth, min_samples_split, min_samples_leaf\n",
    "##### Validation Accuracy: \n",
    "~0.80\n",
    "##### Test Accuracy: \n",
    "~0.79\n",
    "<br>\n",
    "<br>\n",
    "##### Model: \n",
    "Logistic Regression\n",
    "##### Key Tuned Parameters: \n",
    "Solver (liblinear)\n",
    "##### Validation Accuracy: \n",
    "~0.72\n",
    "##### Test Accuracy: \n",
    "~0.71\n",
    "<br>\n",
    "<br>\n",
    "##### Model: \n",
    "Random Forest\n",
    "##### Key Tuned Parameters:\n",
    "n_estimators, max_depth, min_samples_split, min_samples_leaf\n",
    "##### Validation Accuracy: \n",
    "~0.82\n",
    "##### Test Accuracy: \n",
    "~0.82\n",
    "\n",
    "‚∏ª\n",
    "### Best Model: \n",
    "##### Random Forest with:\n",
    "  - n_estimators=150\n",
    "  - max_depth=None\n",
    "  - min_samples_split=2\n",
    "  - min_samples_leaf=1\n",
    "\n",
    "‚∏ª\n",
    "\n",
    "### Sanity Check Findings\n",
    "Training Accuracy: ~0.83\n",
    "<br>Test Accuracy: ~0.79\n",
    "<br>Slight overfitting, expected for Random Forest, but still good generalization.\n",
    "##### Prediction Distribution: \n",
    "Close to the true label distribution, with a slight bias toward predicting Smart plans, reflecting its higher frequency in the dataset.\n",
    "\n",
    "‚∏ª\n",
    "\n",
    "### Business Interpretation\n",
    "\n",
    "An accuracy of ~78.85% means the model recommends the correct plan almost 8 out of 10 times. For Megaline, this can:\n",
    "<br>\t‚Ä¢\tReduce customer dissatisfaction from being placed on an unsuitable plan.\n",
    "<br>\t‚Ä¢\tIncrease adoption of newer plans by matching them more closely to usage habits.\n",
    "<br>\t‚Ä¢\tPotentially lower churn rates and increase customer lifetime value.\n",
    "\n",
    "‚∏ª\n",
    "\n",
    "### Recommendations for Deployment\n",
    "1. Deploy the Random Forest Classifier in Megaline‚Äôs sales and customer self-service systems.\n",
    "2. Monitor accuracy over time and retrain if it falls below 75%.\n",
    "3. Collect additional behavioral features (e.g., roaming frequency, streaming usage) to improve prediction power.\n",
    "4. Consider balancing training data if the Smart plan remains dominant to reduce bias."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "  <b>Reviewer‚Äôs comment ‚Äì Iteration 1:</b><br>\n",
    "  Excellent final summary! You clearly restated the project objective, outlined the models tested, detailed your hyperparameter tuning process, and presented validation/test accuracies for each algorithm. Selecting the Random Forest as the best model is well justified, and your business interpretation and deployment recommendations are practical and actionable. Including a sanity check with prediction distribution analysis adds strong credibility to your results.\n",
    "</div>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
